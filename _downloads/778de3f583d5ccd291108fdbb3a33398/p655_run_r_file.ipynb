{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Running the P655 Reduction File\n\n\nExperiment p655 was run in 2005 by Mckiernan, Rathbun, and Rowe. It was reduced by Chris\nMarone. Here we use the xlook r file parser to run that r file and then get it into the\ndictionary of quantity arrays like we use everywhere else and do some simple plotting of the\nexperiment.\n\nFor the curious, this experiment is determining the frictional response of \"Ghost Rocks\"\nfrom Kodiak Alaska.\n\nFirst we import a few things so we can get at the test data and we import the xlook parser\nobject.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\nfrom pylook.io import XlookParser\nfrom pylook.cbook import get_test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use pooch to get test data when you run this notebook for the first time, so you won't\nhave to use that `get_test_data` function - it's a helper we use to make running pylook\nexamples easy! We run it on the r file and the data file so we're sure that both are\ndownloaded to your system. In your world, you'll just need to set the `r_file_path` variable\nto the path to your r file. We recommend using pathlib to do this so your code is portable\nacross operating systems!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "r_file_path = get_test_data('p655_r')\n\n# Getting the l file as well, just so we're sure it's downloaded!\n_ = get_test_data('p655intact100l')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to create an instance of the parser - this is an object that stores all of the\ncommands and parsing instructions for interpreting r files and running them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "look = XlookParser()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As a hat tip to xlook, we call the `doit` method on our parser to run the r file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "look.doit(r_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just as xlook did, unknown commands are ignored. In this case we see warnings that the\nstrain command is unknown (i.e. we haven't implemented it yet) and there are some follow on\nconsequences from that calculation not happening, but we keep running and get valid output!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The data are currently in a list of arrays in the object, but we want to get the same data\n# structure we work with when dealing with data in pure Python - a dictionary of quantity\n# arrays! That can be tricky because we need to assign units which are sometimes misspelled\n# or just odd. The `get_data_dict` method will do its best, but ultimately fail with unknown\n# units. With the `ignore_unknown_units` argument set to `True` it will warn and assign\n# dimensionless to anything it doesn't understand. You can also manually specify units for\n# all columns, but it is generally easier to fix it up later in practice.\n\nd = look.get_data_dict(ignore_unknown_units=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import our unit registry and fix up the bad units to microns as they should have been.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from pylook.units import units\n\n# Fix up that bad unit name\nd['ec_disp'] = d['ec_disp'] * units('micron')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll use Bokeh to take a quick look at the data. Matplotlib is the best choice for your\npublication plots, but the speed and interactivity of Bokeh in the notebook is hard to beat.\nWe'll be adding helpers to pylook to make this process easier in the future as well.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We need to do some imports from bokeh and turn on the notebook backend.\n\nfrom bokeh.layouts import gridplot, row, column\nfrom bokeh.plotting import figure, output_file, show\nfrom bokeh.io import output_notebook\n\noutput_notebook()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a handy function that will be integrated into pylook in a more advanced way soon,\nbut demonstrates how to make a flexible plotting function instead of copying and pasting a\nbunch of code over and over again.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def make_runplot(data, x_var='Time', y_vars=None, tools='pan,wheel_zoom,box_zoom,reset,save,box_select,hover'):\n    plots = []\n    for col_name in list(data):\n        if col_name == x_var:\n            continue\n        if y_vars and (col_name not in y_vars):\n            continue\n        \n        # First plot is simple, the rest we share the x range with the first\n        if plots == []:\n            p = figure(title=col_name, tools=tools)\n        else:\n            p = figure(title=col_name, tools=tools, x_range=plots[0].x_range)\n        \n        # Plot the data and set the labels\n        p.xaxis.axis_label = str(data[x_var].units)\n        p.yaxis.axis_label = str(data[col_name].units)\n        p.line(data[x_var].m, data[col_name].m)\n        \n        plots.append(p)\n    show(gridplot(plots, ncols=1, plot_width=600, plot_height=175))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default make_runplot would plot all of the variables, let's just plot a couple of basic\nones. Hover over the graph to see the values! That can be turned off by clicking the message\nbubble icon in the plot toolbar. If we don't specify, data are plotted with respect to time.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "make_runplot(d, y_vars=['Shear_stress', 'Nor_stress'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can specify to plot relative to another x variable though - with load point displacement\nprobably being the most common.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "make_runplot(d, x_var='LP_disp', y_vars=['Shear_stress', 'Nor_stress'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's it! Running the r file for an experiment created for xlook is really just a few lines\nand then we can pull it into the pylook framework easily to manipualte that data with all of\nPython's power. For new experiments, we recommend reducing the experiment in pure Python\n(see other examples), but being able to read and look at older experiments with no fiddling\nis important to utilize the massive amounts of data already collected and reduced.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}